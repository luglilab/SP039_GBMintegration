{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06269b01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T12:07:12.614904Z",
     "start_time": "2023-02-09T12:07:10.487373Z"
    }
   },
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import colors\n",
    "import seaborn as sb\n",
    "#from gprofiler import GProfiler\n",
    "#import loompy as lp\n",
    "#import rpy2.rinterface_lib.callbacks\n",
    "import logging\n",
    "#import scrublet as scr\n",
    "#from rpy2.robjects import pandas2ri\n",
    "#import anndata2ri\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "707ac7c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T12:07:14.942852Z",
     "start_time": "2023-02-09T12:07:12.616306Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 13:07:12.751408: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-09 13:07:12.755132: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-09 13:07:12.755142: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os              \n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "import desc\n",
    "#import keras\n",
    "import tensorflow as tf\n",
    "from time import time                                                       \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f74292b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T12:07:16.354217Z",
     "start_time": "2023-02-09T12:07:14.944611Z"
    }
   },
   "outputs": [],
   "source": [
    "adata = sc.read(\"/home/lugli/spuccio/Projects/SP039/FileH5AD_concatenated/adata_annTcell.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d8fb7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T12:07:16.361221Z",
     "start_time": "2023-02-09T12:07:16.356434Z"
    }
   },
   "outputs": [],
   "source": [
    "adata.X = adata.layers['raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00002ec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T12:07:21.068817Z",
     "start_time": "2023-02-09T12:07:16.362384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    }
   ],
   "source": [
    "adata2 = adata.copy()\n",
    "\n",
    "sc.pp.normalize_per_cell(adata2, counts_per_cell_after=1e4)\n",
    "sc.pp.log1p(adata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6261e2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T12:07:47.681707Z",
     "start_time": "2023-02-09T12:07:37.806746Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata2,n_top_genes=4000,subset=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e11f2752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T12:07:53.270284Z",
     "start_time": "2023-02-09T12:07:50.990425Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pp.scale(adata2,max_value=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "774c95c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T12:42:33.143240Z",
     "start_time": "2023-02-09T12:08:23.811985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to process resolution= 0.3\n",
      "The number of cpu in your computer is 48\n",
      "WARNING:tensorflow:From /home/lugli/spuccio/anaconda3/envs/scanpy19/lib/python3.10/site-packages/desc/models/desc.py:123: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "use_ae_weights=False, the program will rerun autoencoder\n",
      "Pretraining the 1th layer...\n",
      "learning rate = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 13:08:24.649671: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-09 13:08:24.654045: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-09 13:08:24.654085: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-09 13:08:24.654117: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node7): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.2168\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.2103\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.2045\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.2012\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1986\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1965\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1948\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1935\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1924\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1914\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1905\n",
      "Epoch 12/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1898\n",
      "Epoch 13/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1891\n",
      "Epoch 14/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1885\n",
      "Epoch 15/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1879\n",
      "Epoch 16/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1875\n",
      "Epoch 17/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1870\n",
      "Epoch 18/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1866\n",
      "Epoch 19/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1862\n",
      "Epoch 20/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1859\n",
      "Epoch 21/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1855\n",
      "Epoch 22/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1852\n",
      "Epoch 23/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1850\n",
      "Epoch 24/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1847\n",
      "Epoch 25/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1844\n",
      "Epoch 26/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1842\n",
      "Epoch 27/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1839\n",
      "Epoch 28/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1837\n",
      "Epoch 29/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1835\n",
      "Epoch 30/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1833\n",
      "Epoch 31/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1831\n",
      "Epoch 32/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1829\n",
      "Epoch 33/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1827\n",
      "Epoch 34/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1825\n",
      "Epoch 35/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1824\n",
      "Epoch 36/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1822\n",
      "Epoch 37/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1821\n",
      "Epoch 38/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1819\n",
      "Epoch 39/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1818\n",
      "Epoch 40/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1817\n",
      "Epoch 41/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1815\n",
      "Epoch 42/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1814\n",
      "Epoch 43/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1813\n",
      "Epoch 44/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1812\n",
      "Epoch 45/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1811\n",
      "Epoch 46/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1810\n",
      "Epoch 47/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1809\n",
      "Epoch 48/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1808\n",
      "Epoch 49/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1808\n",
      "Epoch 50/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1807\n",
      "learning rate = 0.01\n",
      "Epoch 1/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1806\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1806\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1806\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1806\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1806\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1806\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1806\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 11: early stopping\n",
      "learning rate = 0.001\n",
      "Epoch 1/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.1805\n",
      "Epoch 11: early stopping\n",
      "The 1th layer has been pretrained.\n",
      "2804/2804 [==============================] - 4s 1ms/step\n",
      "Pretraining the 2th layer...\n",
      "learning rate = 0.1\n",
      "Epoch 1/50\n",
      "351/351 [==============================] - 1s 2ms/step - loss: 0.4258\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2339\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2156\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2079\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2051\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2022\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2014\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2004\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1990\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1991\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1985\n",
      "Epoch 12/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1983\n",
      "Epoch 13/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1973\n",
      "Epoch 14/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1970\n",
      "Epoch 15/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1956\n",
      "Epoch 16/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1965\n",
      "Epoch 17/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1965\n",
      "Epoch 18/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1967\n",
      "Epoch 19/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1969\n",
      "Epoch 20/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1961\n",
      "Epoch 21/50\n",
      "351/351 [==============================] - 1s 2ms/step - loss: 0.1958\n",
      "Epoch 22/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1967\n",
      "Epoch 23/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1959\n",
      "Epoch 24/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1956\n",
      "Epoch 25/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1967\n",
      "Epoch 25: early stopping\n",
      "learning rate = 0.01\n",
      "Epoch 1/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1906\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1897\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1897\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1907\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1898\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1895\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1888\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 1s 2ms/step - loss: 0.1879\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1890\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1888\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1885\n",
      "Epoch 12/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1884\n",
      "Epoch 13/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1885\n",
      "Epoch 14/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1896\n",
      "Epoch 15/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1881\n",
      "Epoch 16/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1894\n",
      "Epoch 17/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1888\n",
      "Epoch 18/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1887\n",
      "Epoch 18: early stopping\n",
      "learning rate = 0.001\n",
      "Epoch 1/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1879\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 1s 2ms/step - loss: 0.1882\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1888\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1886\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1878\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1875\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1878\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1882\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1880\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1880\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1875\n",
      "Epoch 12/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1877\n",
      "Epoch 13/50\n",
      "351/351 [==============================] - 1s 2ms/step - loss: 0.1880\n",
      "Epoch 14/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1878\n",
      "Epoch 15/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1893\n",
      "Epoch 16/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1871\n",
      "Epoch 17/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1893\n",
      "Epoch 18/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1876\n",
      "Epoch 19/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1878\n",
      "Epoch 20/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1882\n",
      "Epoch 21/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1884\n",
      "Epoch 22/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1885\n",
      "Epoch 23/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1885\n",
      "Epoch 24/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1880\n",
      "Epoch 25/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1877\n",
      "Epoch 26/50\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1877\n",
      "Epoch 26: early stopping\n",
      "The 2th layer has been pretrained.\n",
      "2804/2804 [==============================] - 3s 916us/step\n",
      "Copying layer-wise pretrained weights to deep autoencoders\n",
      "Fine-tuning autoencoder end-to-end\n",
      "learning rate = 1\n",
      "Epoch 1/50\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.1784\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1773\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1768\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1764\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1760\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1758\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1755\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1753\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1751\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1749\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1748\n",
      "Epoch 12/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1747\n",
      "Epoch 13/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1745\n",
      "Epoch 14/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1744\n",
      "Epoch 15/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1743\n",
      "Epoch 16/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1742\n",
      "Epoch 17/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1741\n",
      "Epoch 18/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1740\n",
      "Epoch 19/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1740\n",
      "Epoch 20/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1739\n",
      "Epoch 21/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1738\n",
      "Epoch 22/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1738\n",
      "Epoch 23/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1737\n",
      "Epoch 24/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1736\n",
      "Epoch 25/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1736\n",
      "Epoch 26/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1735\n",
      "Epoch 27/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1735\n",
      "Epoch 28/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1734\n",
      "Epoch 29/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1734\n",
      "Epoch 30/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1733\n",
      "Epoch 31/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1733\n",
      "Epoch 32/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1733\n",
      "Epoch 33/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1732\n",
      "Epoch 34/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1732\n",
      "Epoch 35/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1732\n",
      "Epoch 36/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1731\n",
      "Epoch 37/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1731\n",
      "Epoch 38/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1731\n",
      "Epoch 39/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1730\n",
      "Epoch 40/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1730\n",
      "Epoch 41/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1730\n",
      "Epoch 42/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1729\n",
      "Epoch 43/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1729\n",
      "Epoch 44/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1729\n",
      "Epoch 45/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1729\n",
      "Epoch 46/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1728\n",
      "Epoch 47/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1728\n",
      "Epoch 48/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1728\n",
      "Epoch 49/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1728\n",
      "Epoch 50/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1728\n",
      "learning rate = 0.1\n",
      "Epoch 1/50\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.1726\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1726\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1726\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1726\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1726\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1726\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1726\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1726\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1726\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1726\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1726\n",
      "Epoch 11: early stopping\n",
      "learning rate = 0.01\n",
      "Epoch 1/50\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.1725\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 11: early stopping\n",
      "learning rate = 0.001\n",
      "Epoch 1/50\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.1725\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 11: early stopping\n",
      "learning rate = 0.0001\n",
      "Epoch 1/50\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.1725\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 11: early stopping\n",
      "learning rate = 1e-05\n",
      "Epoch 1/50\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.1725\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.1725\n",
      "Epoch 11: early stopping\n",
      "Pretraining time is 346.1644444465637\n",
      "Pretrained weights are saved to /home/lugli/spuccio/Projects/SP025_NaClTcell/Analysis/Integrated /ae_weights.h5\n",
      "2804/2804 [==============================] - 4s 1ms/step\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.036945373467112595 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0387\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0233\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0191\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0169\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.0155\n",
      "The value of delta_label of current 2 th iteration is 0.03657748049052397 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1177\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0821\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0675\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0586\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0523\n",
      "The value of delta_label of current 3 th iteration is 0.02830546265328874 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1986\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1605\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1401\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1261\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1158\n",
      "The value of delta_label of current 4 th iteration is 0.03072463768115942 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2294\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2047\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1888\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1766\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1667\n",
      "The value of delta_label of current 5 th iteration is 0.024615384615384615 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2218\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2068\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1956\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1864\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1788\n",
      "The value of delta_label of current 6 th iteration is 0.01870680044593088 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2105\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2002\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1926\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1863\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1812\n",
      "The value of delta_label of current 7 th iteration is 0.013322185061315496 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2029\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1958\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1901\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1850\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1807\n",
      "The value of delta_label of current 8 th iteration is 0.007748049052396878 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1961\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1915\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1880\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1852\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1827\n",
      "The value of delta_label of current 9 th iteration is 0.004124860646599777 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1913\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1884\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1859\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1837\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1816\n",
      "The value of delta_label of current 10 th iteration is 0.0026644370122630994 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1869\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1847\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1826\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1808\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1791\n",
      "The value of delta_label of current 11 th iteration is 0.0014381270903010034 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1830\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1812\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1796\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1781\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1768\n",
      "delta_label  0.0009698996655518394 < tol  0.001\n",
      "Reached tolerance threshold. Stop training.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "The final prediction cluster is:\n",
      "0     19716\n",
      "1     15159\n",
      "2     12191\n",
      "3      6965\n",
      "4      9668\n",
      "5      4643\n",
      "6      4624\n",
      "7      3610\n",
      "8      1210\n",
      "9      1185\n",
      "10     2930\n",
      "11     1574\n",
      "12     5732\n",
      "13      493\n",
      "dtype: int64\n",
      "2804/2804 [==============================] - 4s 2ms/step\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 4000)]            0         \n",
      "                                                                 \n",
      " encoder_0 (Dense)           (None, 64)                256064    \n",
      "                                                                 \n",
      " encoder_1 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " clustering (ClusteringLayer  (None, 14)               448       \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 258,592\n",
      "Trainable params: 258,592\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.3)is: 642.7465305328369\n",
      "umap finished and added X_umap0.3  into the umap coordinates (adata.obsm)\n",
      "\n",
      "Start to process resolution= 0.4\n",
      "The number of cpu in your computer is 48\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Checking whether /home/lugli/spuccio/Projects/SP025_NaClTcell/Analysis/Integrated/ae_weights.h5  exists in the directory\n",
      "Pretraining time is 0.009975910186767578\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2804/2804 [==============================] - 4s 2ms/step\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.06723522853957636 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0452\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0296\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0246\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0220\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0202\n",
      "The value of delta_label of current 2 th iteration is 0.04511705685618729 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1453\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1063\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0882\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0767\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0686\n",
      "The value of delta_label of current 3 th iteration is 0.03736900780379041 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2527\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2093\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1841\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1666\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1532\n",
      "The value of delta_label of current 4 th iteration is 0.03534002229654404 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2832\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2568\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2378\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2227\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2105\n",
      "The value of delta_label of current 5 th iteration is 0.030144927536231884 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2813\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2641\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2512\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2409\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2323\n",
      "The value of delta_label of current 6 th iteration is 0.023322185061315497 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2801\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2674\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2577\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2498\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2434\n",
      "The value of delta_label of current 7 th iteration is 0.0163768115942029 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2780\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2694\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2626\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2566\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2511\n",
      "The value of delta_label of current 8 th iteration is 0.011081382385730212 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2752\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2673\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2609\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2554\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2506\n",
      "The value of delta_label of current 9 th iteration is 0.007993311036789299 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2703\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2643\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2592\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2549\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2511\n",
      "The value of delta_label of current 10 th iteration is 0.005373467112597547 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2647\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2600\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2562\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2526\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2494\n",
      "The value of delta_label of current 11 th iteration is 0.003779264214046823 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2587\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2550\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2519\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2490\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2464\n",
      "The value of delta_label of current 12 th iteration is 0.002597547380156076 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2531\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2500\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2473\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2449\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2427\n",
      "The value of delta_label of current 13 th iteration is 0.0014938684503901895 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2479\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2455\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2434\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2415\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2399\n",
      "The value of delta_label of current 14 th iteration is 0.0014158305462653288 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2438\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2421\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2405\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2392\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2380\n",
      "delta_label  0.000903010033444816 < tol  0.001\n",
      "Reached tolerance threshold. Stop training.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "The final prediction cluster is:\n",
      "0     11961\n",
      "1     12528\n",
      "2      8918\n",
      "3     10644\n",
      "4      6966\n",
      "5      6235\n",
      "6      4631\n",
      "7      4146\n",
      "8      3610\n",
      "9      5842\n",
      "10     4744\n",
      "11     1224\n",
      "12     1185\n",
      "13      932\n",
      "14     1335\n",
      "15     2462\n",
      "16     1480\n",
      "17      470\n",
      "18      387\n",
      "dtype: int64\n",
      "2804/2804 [==============================] - 4s 2ms/step\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 4000)]            0         \n",
      "                                                                 \n",
      " encoder_0 (Dense)           (None, 64)                256064    \n",
      "                                                                 \n",
      " encoder_1 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " clustering (ClusteringLayer  (None, 19)               608       \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 258,752\n",
      "Trainable params: 258,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.4)is: 183.9203817844391\n",
      "umap finished and added X_umap0.4  into the umap coordinates (adata.obsm)\n",
      "\n",
      "Start to process resolution= 0.5\n",
      "The number of cpu in your computer is 48\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Checking whether /home/lugli/spuccio/Projects/SP025_NaClTcell/Analysis/Integrated/ae_weights.h5  exists in the directory\n",
      "Pretraining time is 0.010512113571166992\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2804/2804 [==============================] - 4s 2ms/step\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.07270903010033444 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0484\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0325\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0273\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0245\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0227\n",
      "The value of delta_label of current 2 th iteration is 0.04735785953177257 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1524\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1134\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0947\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0826\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0740\n",
      "The value of delta_label of current 3 th iteration is 0.04386845039018952 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2635\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2200\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1942\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1761\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1622\n",
      "The value of delta_label of current 4 th iteration is 0.04012263099219621 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2971\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2696\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2499\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2346\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2223\n",
      "The value of delta_label of current 5 th iteration is 0.036800445930880714 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2978\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2812\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2687\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2585\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2496\n",
      "The value of delta_label of current 6 th iteration is 0.026833890746934225 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2965\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2850\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2758\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2680\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2614\n",
      "The value of delta_label of current 7 th iteration is 0.019442586399108137 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2964\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2872\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2801\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2740\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2689\n",
      "The value of delta_label of current 8 th iteration is 0.012630992196209587 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2962\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2891\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2830\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2774\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2724\n",
      "The value of delta_label of current 9 th iteration is 0.009732441471571906 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2933\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2864\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2804\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2750\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2705\n",
      "The value of delta_label of current 10 th iteration is 0.0064771460423634335 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2877\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2824\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2779\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2740\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2705\n",
      "The value of delta_label of current 11 th iteration is 0.0042474916387959865 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2820\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2779\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2741\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2707\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2678\n",
      "The value of delta_label of current 12 th iteration is 0.0027536231884057972 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2759\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2725\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2694\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2665\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2638\n",
      "The value of delta_label of current 13 th iteration is 0.0021070234113712374 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2701\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2674\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2649\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2626\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2606\n",
      "The value of delta_label of current 14 th iteration is 0.0013043478260869566 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2655\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2633\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2613\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2595\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2578\n",
      "The value of delta_label of current 15 th iteration is 0.0010702341137123746 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2614\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2597\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2581\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2566\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2552\n",
      "delta_label  0.000613154960981048 < tol  0.001\n",
      "Reached tolerance threshold. Stop training.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "The final prediction cluster is:\n",
      "0     12525\n",
      "1      8146\n",
      "2      6914\n",
      "3     10375\n",
      "4      6968\n",
      "5      8123\n",
      "6      6307\n",
      "7      4624\n",
      "8      4148\n",
      "9      3609\n",
      "10     5972\n",
      "11     1184\n",
      "12     1254\n",
      "13      907\n",
      "14     2418\n",
      "15     1515\n",
      "16      632\n",
      "17      619\n",
      "18      476\n",
      "19     2599\n",
      "20      385\n",
      "dtype: int64\n",
      "2804/2804 [==============================] - 4s 2ms/step\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 4000)]            0         \n",
      "                                                                 \n",
      " encoder_0 (Dense)           (None, 64)                256064    \n",
      "                                                                 \n",
      " encoder_1 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " clustering (ClusteringLayer  (None, 21)               672       \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 258,816\n",
      "Trainable params: 258,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.5)is: 194.68742060661316\n",
      "umap finished and added X_umap0.5  into the umap coordinates (adata.obsm)\n",
      "\n",
      "Start to process resolution= 0.6\n",
      "The number of cpu in your computer is 48\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Checking whether /home/lugli/spuccio/Projects/SP025_NaClTcell/Analysis/Integrated/ae_weights.h5  exists in the directory\n",
      "Pretraining time is 0.009413957595825195\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2804/2804 [==============================] - 4s 2ms/step\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.06430323299888517 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0514\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0355\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0303\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0274\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0255\n",
      "The value of delta_label of current 2 th iteration is 0.0420066889632107 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1551\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1169\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0982\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0861\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0774\n",
      "The value of delta_label of current 3 th iteration is 0.03842809364548495 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2687\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2250\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1989\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1804\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1662\n",
      "The value of delta_label of current 4 th iteration is 0.03591973244147157 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3043\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2769\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2572\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2417\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2292\n",
      "The value of delta_label of current 5 th iteration is 0.03798216276477146 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3040\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2861\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2725\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2611\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2514\n",
      "The value of delta_label of current 6 th iteration is 0.034927536231884056 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3021\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2883\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2779\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2693\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2619\n",
      "The value of delta_label of current 7 th iteration is 0.019108138238573023 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3018\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2917\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2838\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2773\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2717\n",
      "The value of delta_label of current 8 th iteration is 0.010724637681159421 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3022\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2943\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2880\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2827\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2781\n",
      "The value of delta_label of current 9 th iteration is 0.007881828316610925 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3007\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2949\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2901\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2859\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2820\n",
      "The value of delta_label of current 10 th iteration is 0.005540691192865106 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2963\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2914\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2870\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2830\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2793\n",
      "The value of delta_label of current 11 th iteration is 0.003645484949832776 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2901\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2861\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2825\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2793\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2766\n",
      "The value of delta_label of current 12 th iteration is 0.0026755852842809363 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2847\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2818\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2790\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2766\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2743\n",
      "The value of delta_label of current 13 th iteration is 0.0015384615384615385 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2799\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2773\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2749\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2728\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2708\n",
      "The value of delta_label of current 14 th iteration is 0.0011259754738015607 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2752\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2732\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2712\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2694\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2678\n",
      "delta_label  0.0008472686733556299 < tol  0.001\n",
      "Reached tolerance threshold. Stop training.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "The final prediction cluster is:\n",
      "0     12510\n",
      "1     10056\n",
      "2      5870\n",
      "3      6260\n",
      "4      8237\n",
      "5      6968\n",
      "6      7768\n",
      "7      5423\n",
      "8      4625\n",
      "9      3265\n",
      "10     3609\n",
      "11     4918\n",
      "12     1184\n",
      "13     1168\n",
      "14      880\n",
      "15     2400\n",
      "16     1569\n",
      "17      616\n",
      "18      611\n",
      "19     1058\n",
      "20      469\n",
      "21      236\n",
      "dtype: int64\n",
      "2804/2804 [==============================] - 4s 2ms/step\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 4000)]            0         \n",
      "                                                                 \n",
      " encoder_0 (Dense)           (None, 64)                256064    \n",
      "                                                                 \n",
      " encoder_1 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " clustering (ClusteringLayer  (None, 22)               704       \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 258,848\n",
      "Trainable params: 258,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.6)is: 179.2735414505005\n",
      "umap finished and added X_umap0.6  into the umap coordinates (adata.obsm)\n",
      "\n",
      "Start to process resolution= 0.7\n",
      "The number of cpu in your computer is 48\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Checking whether /home/lugli/spuccio/Projects/SP025_NaClTcell/Analysis/Integrated/ae_weights.h5  exists in the directory\n",
      "Pretraining time is 0.00976872444152832\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2804/2804 [==============================] - 4s 2ms/step\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.0760200668896321 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0553\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0395\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0340\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0309\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0287\n",
      "The value of delta_label of current 2 th iteration is 0.0451505016722408 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1606\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1240\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1053\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0930\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0840\n",
      "The value of delta_label of current 3 th iteration is 0.04862876254180602 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2712\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2296\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2040\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1855\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1713\n",
      "The value of delta_label of current 4 th iteration is 0.03809364548494983 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3098\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2824\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2629\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2478\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2357\n",
      "The value of delta_label of current 5 th iteration is 0.039186176142697884 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3121\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2951\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2822\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2714\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2620\n",
      "The value of delta_label of current 6 th iteration is 0.037235228539576365 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3092\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2956\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2851\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2763\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2687\n",
      "The value of delta_label of current 7 th iteration is 0.03906354515050167 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3046\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2944\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2861\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2790\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2728\n",
      "The value of delta_label of current 8 th iteration is 0.03166109253065775 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2995\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2915\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2851\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2797\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2749\n",
      "The value of delta_label of current 9 th iteration is 0.0162876254180602 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2975\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2914\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2866\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2826\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2789\n",
      "The value of delta_label of current 10 th iteration is 0.009163879598662208 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3001\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2944\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2902\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2866\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2835\n",
      "The value of delta_label of current 11 th iteration is 0.006822742474916388 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3047\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2998\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2962\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2930\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2901\n",
      "The value of delta_label of current 12 th iteration is 0.0052396878483835 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3070\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3025\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2988\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2955\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2925\n",
      "The value of delta_label of current 13 th iteration is 0.004002229654403567 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3061\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3023\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2992\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2965\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2940\n",
      "The value of delta_label of current 14 th iteration is 0.0027536231884057972 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3029\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3000\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2976\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2954\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2934\n",
      "The value of delta_label of current 15 th iteration is 0.0021070234113712374 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2993\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2971\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2953\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2936\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2919\n",
      "The value of delta_label of current 16 th iteration is 0.0014381270903010034 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2960\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2939\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2920\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2901\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2882\n",
      "delta_label  0.0009364548494983278 < tol  0.001\n",
      "Reached tolerance threshold. Stop training.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "The final prediction cluster is:\n",
      "0     12834\n",
      "1      5304\n",
      "2     10107\n",
      "3      6983\n",
      "4      6967\n",
      "5      7466\n",
      "6      4931\n",
      "7      4615\n",
      "8      3610\n",
      "9      4747\n",
      "10     2312\n",
      "11     4379\n",
      "12     4644\n",
      "13     1096\n",
      "14     2047\n",
      "15     1236\n",
      "16     1186\n",
      "17      854\n",
      "18     1163\n",
      "19     1027\n",
      "20      716\n",
      "21      465\n",
      "22      878\n",
      "23      133\n",
      "dtype: int64\n",
      "2804/2804 [==============================] - 4s 2ms/step\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 4000)]            0         \n",
      "                                                                 \n",
      " encoder_0 (Dense)           (None, 64)                256064    \n",
      "                                                                 \n",
      " encoder_1 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " clustering (ClusteringLayer  (None, 24)               768       \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 258,912\n",
      "Trainable params: 258,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.7)is: 200.1087884902954\n",
      "umap finished and added X_umap0.7  into the umap coordinates (adata.obsm)\n",
      "\n",
      "Start to process resolution= 0.8\n",
      "The number of cpu in your computer is 48\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Checking whether /home/lugli/spuccio/Projects/SP025_NaClTcell/Analysis/Integrated/ae_weights.h5  exists in the directory\n",
      "Pretraining time is 0.010016679763793945\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2804/2804 [==============================] - 4s 2ms/step\n",
      "...number of clusters is unknown, Initialize cluster centroid using louvain method\n",
      "The value of delta_label of current 1 th iteration is 0.07711259754738016 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0580\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0423\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0367\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0335\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0312\n",
      "The value of delta_label of current 2 th iteration is 0.04703455964325529 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1647\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1290\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1104\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0980\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.0890\n",
      "The value of delta_label of current 3 th iteration is 0.05196209587513936 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2748\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2339\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2085\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1899\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.1755\n",
      "The value of delta_label of current 4 th iteration is 0.05185061315496098 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3135\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2862\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2668\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2516\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2392\n",
      "The value of delta_label of current 5 th iteration is 0.0493422519509476 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3174\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2999\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2866\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2756\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2662\n",
      "The value of delta_label of current 6 th iteration is 0.04981047937569677 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3194\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3065\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2966\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2880\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2805\n",
      "The value of delta_label of current 7 th iteration is 0.032486064659977706 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3233\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3127\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3043\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2972\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2911\n",
      "The value of delta_label of current 8 th iteration is 0.02439241917502787 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3269\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3182\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3109\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3045\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.2988\n",
      "The value of delta_label of current 9 th iteration is 0.026231884057971014 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3282\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3207\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3146\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3093\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3046\n",
      "The value of delta_label of current 10 th iteration is 0.018149386845039018 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3277\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3217\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3167\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3125\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3087\n",
      "The value of delta_label of current 11 th iteration is 0.012686733556298773 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3273\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3225\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3184\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3148\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3114\n",
      "The value of delta_label of current 12 th iteration is 0.0071906354515050164 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3271\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3231\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3195\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3163\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3133\n",
      "The value of delta_label of current 13 th iteration is 0.005618729096989967 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3260\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3224\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3191\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3161\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3134\n",
      "The value of delta_label of current 14 th iteration is 0.003946488294314382 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3240\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3211\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3184\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3159\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3137\n",
      "The value of delta_label of current 15 th iteration is 0.0033779264214046823 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3222\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3199\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3177\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3157\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3139\n",
      "The value of delta_label of current 16 th iteration is 0.0026421404682274246 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3200\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3179\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3160\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3140\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3124\n",
      "The value of delta_label of current 17 th iteration is 0.0016164994425863991 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3173\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3154\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3135\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3117\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3102\n",
      "The value of delta_label of current 18 th iteration is 0.0012931995540691192 >= tol 0.001\n",
      "Epoch 1/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3142\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3125\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3109\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3093\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.3079\n",
      "delta_label  0.0009141583054626533 < tol  0.001\n",
      "Reached tolerance threshold. Stop training.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "The final prediction cluster is:\n",
      "0     12306\n",
      "1      9056\n",
      "2      3605\n",
      "3      6967\n",
      "4      6956\n",
      "5      7040\n",
      "6      5019\n",
      "7      3474\n",
      "8      4609\n",
      "9      3610\n",
      "10     2327\n",
      "11     4205\n",
      "12     5113\n",
      "13     4111\n",
      "14     1379\n",
      "15     1186\n",
      "16     1213\n",
      "17     1126\n",
      "18     1569\n",
      "19      881\n",
      "20     1032\n",
      "21      668\n",
      "22      466\n",
      "23      881\n",
      "24      770\n",
      "25      131\n",
      "dtype: int64\n",
      "2804/2804 [==============================] - 4s 2ms/step\n",
      "The desc has been trained successfully!!!!!!\n",
      "The summary of desc model is:\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 4000)]            0         \n",
      "                                                                 \n",
      " encoder_0 (Dense)           (None, 64)                256064    \n",
      "                                                                 \n",
      " encoder_1 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " clustering (ClusteringLayer  (None, 26)               832       \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 258,976\n",
      "Trainable params: 258,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The runtime of (resolution=0.8)is: 221.68707585334778\n",
      "umap finished and added X_umap0.8  into the umap coordinates (adata.obsm)\n",
      "\n",
      "The run time for all resolution is: 2049.3223700523376\n",
      "After training, the information of adata is:\n",
      " AnnData object with n_obs  n_vars = 89700  4000\n",
      "    obs: 'SampleID', 'GEO_RNA', 'Cohort', 'Type', 'Subtype', 'Diagnosis', 'Grade', 'Location', 'IDH1_Status', 'EGFR_Status', 'MGMT', 'CellCount', 'Sample', 'Sex', 'Age', 'Sorted', 'MET', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'batch', 'predicted_labels', 'over_clustering', 'majority_voting', 'conf_score', 'desc_0.3', 'desc_0.4', 'desc_0.5', 'desc_0.6', 'desc_0.7', 'desc_0.8'\n",
      "    var: 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n",
      "    uns: 'hvg', 'leiden', 'log1p', 'pca', 'umap', 'prob_matrix0.3', 'prob_matrix0.4', 'prob_matrix0.5', 'prob_matrix0.6', 'prob_matrix0.7', 'prob_matrix0.8'\n",
      "    obsm: 'X_pca', 'X_pca_harmony', 'X_umap', 'X_umap_harmony', 'X_Embeded_z0.3', 'X_umap0.3', 'X_Embeded_z0.4', 'X_umap0.4', 'X_Embeded_z0.5', 'X_umap0.5', 'X_Embeded_z0.6', 'X_umap0.6', 'X_Embeded_z0.7', 'X_umap0.7', 'X_Embeded_z0.8', 'X_umap0.8'\n",
      "    varm: 'PCs'\n",
      "    layers: 'cpm', 'raw'\n",
      "    obsp: 'connectivities', 'distances'\n"
     ]
    }
   ],
   "source": [
    "save_dir=\"/home/lugli/spuccio/Projects/SP025_NaClTcell/Analysis/Integrated\"\n",
    "adata2=desc.train(adata2,\n",
    "        dims=[adata2.shape[1],64,32],\n",
    "        tol=0.001,\n",
    "        n_neighbors=10,\n",
    "        batch_size=256,\n",
    "        louvain_resolution=[0.3,0.4,0.5,0.6,0.7,0.8],# not necessarily a list, you can only set one value, like, louvain_resolution=1.0\n",
    "        save_dir=str(save_dir),\n",
    "        do_tsne=False,\n",
    "        learning_rate=200, # the parameter of tsne\n",
    "        use_GPU=False,\n",
    "        num_Cores=30, #for reproducible, only use 1 cpu\n",
    "        num_Cores_tsne=4,\n",
    "        save_encoder_weights=False,\n",
    "        save_encoder_step=3,# save_encoder_weights is False, this parameter is not used\n",
    "        use_ae_weights=False,\n",
    "        do_umap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8b728f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T12:43:58.133351Z",
     "start_time": "2023-02-09T12:43:58.121153Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11159cdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T12:45:03.132431Z",
     "start_time": "2023-02-09T12:45:03.109589Z"
    }
   },
   "outputs": [],
   "source": [
    "adata.obs = adata2.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "749b1d65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T12:46:23.993546Z",
     "start_time": "2023-02-09T12:46:23.457865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: dendrogram data not found (using key=dendrogram_desc_0.7). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 352.08x676.8 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc.pl.dotplot(adata, ['CD3E','CD8A',\"CD4\",\"FOXP3\",\"GZMB\",\"ENTPD1\",\"TOX\"], groupby='desc_0.7', dendrogram=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4de6a651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T12:49:16.388187Z",
     "start_time": "2023-02-09T12:49:16.303510Z"
    }
   },
   "outputs": [],
   "source": [
    "adataCD8 = adata[adata.obs['desc_0.7'].isin([12,1,11,6,17,5,2,19,4,7]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "581a8892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T12:49:40.773891Z",
     "start_time": "2023-02-09T12:49:37.288970Z"
    }
   },
   "outputs": [],
   "source": [
    "adataCD8.write(\"/home/lugli/spuccio/Projects/SP039/FileH5AD_concatenated/adata_annTcellCD8.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f52df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scanpy19]",
   "language": "python",
   "name": "conda-env-scanpy19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
